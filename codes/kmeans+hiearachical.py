# -*- coding: utf-8 -*-
"""DM1.1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GIqvdiPcQ5Olpu1fSbkvWO7KZmkUDwk5
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import silhouette_samples, silhouette_score
from scipy.cluster.hierarchy import dendrogram, linkage
import scipy.cluster.hierarchy 
from sklearn.cluster import AgglomerativeClustering

#preprocessing:
df=pd.read_csv('DataSamp0.csv')
data=df.drop(['CustomerID'], axis=1)
continuous_features = ['Age','Annual Income (k$)','Spending Score (1-100)']
#convert Gender to binary feature
labelencoder_X = LabelEncoder() 
data['Genre'] = labelencoder_X.fit_transform(data['Genre']) #0-> female 1->male
print(data.head())
#standard scaler ta be hameye feature ha ahamiate yeksan dade beshe
#y=data['Spending Score (1-100)']
#x=data.drop('Spending Score (1-100)',axis=1)
mms = MinMaxScaler()
mms.fit(data)
Data = mms.transform(data)
Data=df.iloc[:, [2, 4]].values
#choose optimal k:
SSE=[]
K=range(1,30)
for k in K:
    model=KMeans(n_clusters=k)
    model=model.fit(Data)
    SSE.append(model.inertia_)
plt.plot(K, SSE, 'bx-')
plt.xlabel('k')
plt.ylabel('SSE')
plt.title('Elbow Method For Optimal k')
plt.show()

#Kmeans on Optimal K
#K=5
optimK=11
kmeans = KMeans(n_clusters = optimK, init = 'k-means++')
y_pred = kmeans.fit_predict(Data)
plt.figure(figsize=(10,10))
plt.scatter(Data[y_pred == 0, 0], Data[y_pred == 0, 1], s = 100, c = 'blue', label = 'Cluster1')
plt.scatter(Data[y_pred == 1, 0], Data[y_pred == 1, 1], s = 100, c = 'red', label = 'Cluster2')
plt.scatter(Data[y_pred == 2, 0], Data[y_pred == 2, 1], s = 100, c = 'green', label = 'Cluster3')
plt.scatter(Data[y_pred == 3, 0], Data[y_pred == 3, 1], s = 100, c = 'cyan', label = 'Cluster4')
plt.scatter(Data[y_pred == 4, 0], Data[y_pred == 4, 1], s = 100, c = 'magenta', label = 'Cluster5')
plt.scatter(Data[y_pred == 5, 0], Data[y_pred == 5, 1], s = 100, c = 'yellow', label = 'Cluster6')
plt.scatter(Data[y_pred == 6, 0], Data[y_pred == 6, 1], s = 100, c = 'tomato', label = 'Cluster7')
plt.scatter(Data[y_pred == 7, 0], Data[y_pred == 7, 1], s = 100, c = 'orchid', label = 'Cluster8')
plt.scatter(Data[y_pred == 8, 0], Data[y_pred == 8, 1], s = 100, c = 'indigo', label = 'Cluster9')
plt.scatter(Data[y_pred == 9, 0], Data[y_pred == 9, 1], s = 100, c = 'orange', label = 'Cluster10')
plt.scatter(Data[y_pred == 10, 0], Data[y_pred == 10, 1], s = 100, c = 'darkslategray', label = 'Cluster11')
plt.title('Clusters of Customers using K-Means Clustering')
plt.xlabel('Annual Income (K$)')
plt.ylabel('Spend Score (1-100)')
plt.legend()
plt.show()

#Hierarichal:
plt.figure(figsize=(10,10))
plt.title("Hierarichal")
dend = scipy.cluster.hierarchy.dendrogram(scipy.cluster.hierarchy.linkage(Data, method='ward'))

cluster = AgglomerativeClustering(n_clusters=11, affinity='euclidean', linkage='ward')
y_pred=cluster.fit_predict(Data)
plt.figure(figsize=(10,10))
plt.scatter(Data[y_pred == 0, 0], Data[y_pred == 0, 1], s = 100, c = 'blue', label = 'Cluster1')
plt.scatter(Data[y_pred == 1, 0], Data[y_pred == 1, 1], s = 100, c = 'red', label = 'Cluster2')
plt.scatter(Data[y_pred == 2, 0], Data[y_pred == 2, 1], s = 100, c = 'green', label = 'Cluster3')
plt.scatter(Data[y_pred == 3, 0], Data[y_pred == 3, 1], s = 100, c = 'cyan', label = 'Cluster4')
plt.scatter(Data[y_pred == 4, 0], Data[y_pred == 4, 1], s = 100, c = 'magenta', label = 'Cluster5')
plt.scatter(Data[y_pred == 5, 0], Data[y_pred == 5, 1], s = 100, c = 'yellow', label = 'Cluster6')
plt.scatter(Data[y_pred == 6, 0], Data[y_pred == 6, 1], s = 100, c = 'tomato', label = 'Cluster7')
plt.scatter(Data[y_pred == 7, 0], Data[y_pred == 7, 1], s = 100, c = 'orchid', label = 'Cluster8')
plt.scatter(Data[y_pred == 8, 0], Data[y_pred == 8, 1], s = 100, c = 'indigo', label = 'Cluster9')
plt.scatter(Data[y_pred == 9, 0], Data[y_pred == 9, 1], s = 100, c = 'orange', label = 'Cluster10')
plt.scatter(Data[y_pred == 10, 0], Data[y_pred == 10, 1], s = 100, c = 'darkslategray', label = 'Cluster11')
plt.title('Clusters of Customers using Hierarchical Clustering')
plt.xlabel('Annual Income (K$)')
plt.ylabel('Spend Score (1-100)')
plt.legend()
plt.show()
